<!doctype html>
<html>
  <head>
    <title>Convolutional Pose Machines</title>
    <link href="css/main.css" media="screen" rel="stylesheet" type="text/css"/>
    <script src="js/jquery/jquery.min.js" type="text/javascript"></script>
    <script src="js/main.js" type="text/javascript"></script>
  </head>
  <body>
    <div id="container">
      <div id="header">
        <div id="header-titles">
          Convolutional Pose Machines
        </div>
        <div id="header-arthors">
          <a href="https://www.linkedin.com/pub/shih-en-wei/86/545/a92">Shih-En Wei</a> &nbsp;&nbsp;&nbsp; <a href="http://www.cs.cmu.edu/~vramakri/">Varun Ramakrishna</a> &nbsp;&nbsp;&nbsp; <a href="">Takeo Kanade</a> &nbsp;&nbsp;&nbsp; <a href="http://www.cs.cmu.edu/~yaser/">Yaser Sheikh</a>
        </div>
        <div id="header-institute">
          <a href="https://www.ri.cmu.edu/">The Robotics Institute</a> &nbsp;&nbsp;&nbsp; <a href="http://www.cmu.edu/">Carnegie Mellon University</a>
        </div>
      </div>
      <div id="video">
        <h3 id="video-title">Demo Videos (frame by frame detection)</h3>
        <p id="video-names">
           <a href="javascript:void(0)" data-value="1" id="s1" class="video-item">Solo Dance</a>&nbsp;|&nbsp;
           <a href="javascript:void(0)" data-value="2" id="s2" class="video-item">Dancing Cop</a>&nbsp;|&nbsp;
           <a href="javascript:void(0)" data-value="3" id="s3" class="video-item">Roger & Rafa</a>&nbsp;|&nbsp;
           <a href="javascript:void(0)" data-value="4" id="s4" class="video-item">Oculus</a>&nbsp;|&nbsp;
           <a href="javascript:void(0)" data-value="5" id="s5" class="video-item">Ronaldinho</a>
        </p>
        <!--p id="video-explanation">Model trained on MPII dataset</p>-->
        <div id="video-container">
          <video class="vinstance" controls="controls" src="video/CVPR/solodance_heatmap_CVPR.mp4" width="860"></video>
          <!--video class="vinstance" controls="controls" src="video/cop_video2.m4v" height="400"></video>-->
          <!--video class="vinstance" controls="controls" src="video/freestyle.mp4" height="400"></video>
          <video class="vinstance" controls="controls" src="video/ronaldinho_new.mov" height="400"></video>
          <video class="vinstance" controls="controls" src="video/safe_cycling2.m4v" height="400"></video>-->
        </div>
      </div>
      <div id="body">
        <div id="body-abstract">
          <h3>Overview</h3> 
          <p>
Pose Machines provide a sequential prediction framework for learning rich implicit spatial models. In this work we show a systematic design for how convolutional networks can be incorporated into the pose machine framework for learning image and image-dependent spatial context for the task of pose estimation. The contribution of this paper is to implicitly model long-range dependencies between variables in structured prediction tasks such as articulated pose estimation. We achieve this by designing a sequential architecture composed of convolutional networks that directly operate on belief maps from previous stages, producing increasingly refined estimates for part locations, without the need for explicit graphical model-style inference. Our approach addresses the characteristic difficulty of vanishing gradients during training by providing a natural learning objective function that enforces intermediate supervision, thereby replenishing back-propagated gradients and conditioning the learning procedure. We demonstrate state-of-the-art performance and outperform competing methods on standard
          benchmarks including <a href="http://human-pose.mpi-inf.mpg.de/">MPII</a>, <a href="http://bensapp.github.io/flic-dataset.html">FLIC</a> and <a href="http://www.comp.leeds.ac.uk/mat4saj/lsp.html">LEEDS Sport Dataset</a>.</p>
        </div>
        <div id="body-img">
          <img src="img/teaser.png" height="455" />
        </div>
      </div>
    </div>
  </body>
</html>
